{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "siU6MLd-YN9s"
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import docx\n",
    "import re\n",
    "from docx import Document\n",
    "from docx.table import Table\n",
    "from docx.text.paragraph import Paragraph\n",
    "from docx.oxml.ns import qn\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_block_items(doc):\n",
    "    for block in doc.element.body:\n",
    "        if block.tag.endswith('}p'):\n",
    "            yield Paragraph(block, doc)\n",
    "        elif block.tag.endswith('}tbl'):\n",
    "            yield Table(block, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_image(paragraph):\n",
    "    return any('graphic' in r.tag.lower() for r in paragraph._element.iter())\n",
    "\n",
    "def extract_images_from_paragraph(paragraph):\n",
    "    image_bytes_list = []\n",
    "    for shape in paragraph._element.iter():\n",
    "        if shape.tag.endswith('}blip'):\n",
    "            rId = shape.get(qn('r:embed'))\n",
    "            image_part = paragraph.part.related_parts[rId]\n",
    "            image_bytes = image_part.blob\n",
    "            image_bytes_list.append(image_bytes)\n",
    "    return image_bytes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_block_items(doc):\n",
    "    for block in doc.element.body:\n",
    "        tag = block.tag.lower()\n",
    "        if tag.endswith('}p'):\n",
    "            yield Paragraph(block, doc)\n",
    "        elif tag.endswith('}tbl'):\n",
    "            yield Table(block, doc)\n",
    "        elif tag.endswith('}sectpr'):\n",
    "            continue  # skip section properties\n",
    "        else:\n",
    "            yield block\n",
    "\n",
    "def has_image(paragraph):\n",
    "    return any('graphic' in r.tag.lower() for r in paragraph._element.iter())\n",
    "\n",
    "def extract_images_from_paragraph(paragraph):\n",
    "    image_bytes_list = []\n",
    "    for shape in paragraph._element.iter():\n",
    "        if shape.tag.endswith('}blip'):\n",
    "            rId = shape.get(qn('r:embed'))\n",
    "            image_part = paragraph.part.related_parts[rId]\n",
    "            image_bytes = image_part.blob\n",
    "            image_bytes_list.append(image_bytes)\n",
    "    return image_bytes_list\n",
    "\n",
    "def contains_equation(paragraph):\n",
    "    for elem in paragraph._element.iter():\n",
    "        if \"oMath\" in elem.tag or \"oMathPara\" in elem.tag:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def scan_document():\n",
    "    global input_path\n",
    "    input_path = 'documents/input.docx'\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"Input file not found: {input_path}\")\n",
    "        return\n",
    "\n",
    "    doc = Document(input_path)\n",
    "    print(\"Scanning Document...\\n\")\n",
    "\n",
    "    image_counter = 1\n",
    "\n",
    "    for block in iter_block_items(doc):\n",
    "        if isinstance(block, Paragraph):\n",
    "            text = block.text.strip()[:60]\n",
    "            style = block.style.name.lower()\n",
    "\n",
    "            if contains_equation(block):\n",
    "                print(f\"Equation: {text}\")\n",
    "            elif 'heading' in style:\n",
    "                match = re.search(r'heading (\\d+)', style)\n",
    "                if match:\n",
    "                    print(f\"Heading {match.group(1)}: {text}\")\n",
    "                else:\n",
    "                    print(f\"Heading (untyped): {text}\")\n",
    "            elif 'caption' in style:\n",
    "                print(f\"Caption: {text}\")\n",
    "            elif text:\n",
    "                print(f\"Paragraph: {text}\")\n",
    "            else:\n",
    "                print(\"Empty Paragraph\")\n",
    "\n",
    "            if has_image(block):\n",
    "                images = extract_images_from_paragraph(block)\n",
    "                for img_bytes in images:\n",
    "                    try:\n",
    "                        img = Image.open(BytesIO(img_bytes))\n",
    "                        print(f\"Image {image_counter} — Format: {img.format}, Size: {img.size}\")\n",
    "                        image_counter += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"Failed to load image: {e}\")\n",
    "\n",
    "        elif isinstance(block, Table):\n",
    "            print(\"Table\")\n",
    "\n",
    "        else:\n",
    "            raw_tag = block.tag if hasattr(block, 'tag') else str(type(block))\n",
    "            print(f\"Unknown Block — Tag: {raw_tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning Document...\n",
      "\n",
      "Heading 1: INTRODUCTION\n",
      "Paragraph: Aerial manipulation systems that use powered grippers operat\n",
      "Caption: title\n",
      "Image 1 — Format: PNG, Size: (596, 512)\n",
      "Empty Paragraph\n",
      "Paragraph: Designs that maintain object retention without continuous en\n",
      "Paragraph: The tendon-actuated soft gripper developed in this study eng\n",
      "Empty Paragraph\n",
      "Table\n",
      "Empty Paragraph\n",
      "Paragraph: Drone integration in Urban Search and Rescue (USAR) missions\n",
      "Heading 2: 1.3 Current Challenge: Drone’s Endurance\n",
      "Empty Paragraph\n",
      "Empty Paragraph\n",
      "Image 2 — Format: PNG, Size: (1429, 760)\n",
      "Caption: evolution\n",
      "Paragraph: Collaborative drone systems apply sequential task transfer, \n"
     ]
    }
   ],
   "source": [
    "scan_document()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph 1: Aerial manipulation systems that use powered grippers operate through continuous motor or pneumatic actuation to maintain object retention. Energy allocated to gripping limits the power available for propulsion and onboard tasks. Rigid components, motorized linkages, and pressurized mechanisms contribute additional structural mass and require fine-tuned control.\n",
      "Paragraph 2: Designs that maintain object retention without continuous energy draw demand less from the drone’s actuation system. Existing aerial docking and modular battery exchange systems incorporate powered gripping subsystems that account for over 7% of total energy expenditure during flight cycles (Jain et al., 2020; Choi et al., 2022; Seth et al., 2024). Hardware required for active control and actuation increases component count and limits adaptability across platforms.\n",
      "Paragraph 3: The tendon-actuated soft gripper developed in this study engages through orthogonal deformation and mechanical tension embedded in a compliant structure. Grip remains engaged after actuation without requiring ongoing power input. Payloads, including external battery modules, remain secured during aerial transport through passive retention alone. The configuration accommodates energy-constrained manipulation tasks involving object handling, battery module transfer, and mid-flight payload exchange.\n",
      "Paragraph 4: Drone integration in Urban Search and Rescue (USAR) missions initially focused on providing aerial imagery for damage assessment. The three-dimensional (3D) Robotics RTF Y6 multicopter, introduced in the early 2010s, featured basic onboard cameras that enabled responders to survey collapsed structures without entering hazardous zones. Early models such as the Y6 multicopter were constrained by short flight durations (under 10 minutes) and minimal payload capacity (below 1 kg), which limited their operational scope. Although the Y6 multicopter enabled basic aerial assessments of unstable environments, its technical limitations prevented applications such as carrying sensor arrays, transporting lightweight supplies, or performing targeted object manipulation.\n",
      "Paragraph 5: Collaborative drone systems apply sequential task transfer, where operational responsibility shifts between multiple drones to maintain uninterrupted activity. One drone executes a segment of the mission, then departs to replace or recharge its battery, while a second drone continues the task from the same location. Enemark (2020) frames the process as a relay-based strategy designed to minimize downtime. Bastos (2022) develop allocation algorithms that determine when and how drones switch roles based on energy levels and mission priorities. Nordin (2022) describes multi-agent architectures that coordinate drone behavior for distributed task sharing. The need for one standby drone per active unit restricts deployment scale in operations involving broad coverage or high-frequency assignments.\n"
     ]
    }
   ],
   "source": [
    "def extract_paragraphs(file_path):\n",
    "    doc = Document(file_path)\n",
    "    paragraphs = []\n",
    "    for para in doc.paragraphs:\n",
    "        style = para.style.name.lower()\n",
    "        if style in [\"normal\", \"body text\"]:  # Only include plain paragraphs\n",
    "            text = para.text.strip()\n",
    "            if text:\n",
    "                paragraphs.append(text)\n",
    "    return paragraphs\n",
    "\n",
    "paragraph_list = extract_paragraphs(input_path)\n",
    "\n",
    "# Preview first few paragraphs\n",
    "for i, p in enumerate(paragraph_list[:]):\n",
    "    print(f\"Paragraph {i+1}: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 20 total sentences.\n",
      "\n",
      "Sentence 1: Aerial manipulation systems that use powered grippers operate through continuous motor or pneumatic actuation to maintain object retention.\n",
      "\n",
      "Sentence 2: Energy allocated to gripping limits the power available for propulsion and onboard tasks.\n",
      "\n",
      "Sentence 3: Rigid components, motorized linkages, and pressurized mechanisms contribute additional structural mass and require fine-tuned control.\n",
      "\n",
      "Sentence 4: Designs that maintain object retention without continuous energy draw demand less from the drone’s actuation system.\n",
      "\n",
      "Sentence 5: Existing aerial docking and modular battery exchange systems incorporate powered gripping subsystems that account for over 7% of total energy expenditure during flight cycles (Jain et al., 2020; Choi et al., 2022; Seth et al., 2024).\n",
      "\n",
      "Sentence 6: Hardware required for active control and actuation increases component count and limits adaptability across platforms.\n",
      "\n",
      "Sentence 7: The tendon-actuated soft gripper developed in this study engages through orthogonal deformation and mechanical tension embedded in a compliant structure.\n",
      "\n",
      "Sentence 8: Grip remains engaged after actuation without requiring ongoing power input.\n",
      "\n",
      "Sentence 9: Payloads, including external battery modules, remain secured during aerial transport through passive retention alone.\n",
      "\n",
      "Sentence 10: The configuration accommodates energy-constrained manipulation tasks involving object handling, battery module transfer, and mid-flight payload exchange.\n",
      "\n",
      "Sentence 11: Drone integration in Urban Search and Rescue (USAR) missions initially focused on providing aerial imagery for damage assessment.\n",
      "\n",
      "Sentence 12: The three-dimensional (3D) Robotics RTF Y6 multicopter, introduced in the early 2010s, featured basic onboard cameras that enabled responders to survey collapsed structures without entering hazardous zones.\n",
      "\n",
      "Sentence 13: Early models such as the Y6 multicopter were constrained by short flight durations (under 10 minutes) and minimal payload capacity (below 1 kg), which limited their operational scope.\n",
      "\n",
      "Sentence 14: Although the Y6 multicopter enabled basic aerial assessments of unstable environments, its technical limitations prevented applications such as carrying sensor arrays, transporting lightweight supplies, or performing targeted object manipulation.\n",
      "\n",
      "Sentence 15: Collaborative drone systems apply sequential task transfer, where operational responsibility shifts between multiple drones to maintain uninterrupted activity.\n",
      "\n",
      "Sentence 16: One drone executes a segment of the mission, then departs to replace or recharge its battery, while a second drone continues the task from the same location.\n",
      "\n",
      "Sentence 17: Enemark (2020) frames the process as a relay-based strategy designed to minimize downtime.\n",
      "\n",
      "Sentence 18: Bastos (2022) develop allocation algorithms that determine when and how drones switch roles based on energy levels and mission priorities.\n",
      "\n",
      "Sentence 19: Nordin (2022) describes multi-agent architectures that coordinate drone behavior for distributed task sharing.\n",
      "\n",
      "Sentence 20: The need for one standby drone per active unit restricts deployment scale in operations involving broad coverage or high-frequency assignments.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def simple_sentence_split(text):\n",
    "    # Splits on period, question mark, or exclamation, followed by space and a capital letter\n",
    "    return re.split(r'(?<=[\\.\\?\\!])\\s+(?=[A-Z])', text)\n",
    "\n",
    "# paragraph_list is assumed to be already defined\n",
    "all_sentences = []\n",
    "\n",
    "for paragraph in paragraph_list:\n",
    "    sentences = simple_sentence_split(paragraph)\n",
    "    all_sentences.extend(sentences)\n",
    "\n",
    "print(f\"Split into {len(all_sentences)} total sentences.\\n\")\n",
    "\n",
    "for idx, sentence in enumerate(all_sentences, start=1):\n",
    "    print(f\"Sentence {idx}: {sentence}\"+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your Gemini API Key manually\n",
    "GEMINI_API_KEY = \"AIzaSyAKVcYFqUH-SIWpsiz127xE3cZmmgNgG7Y\"  # Replace with your actual API key\n",
    "genai.configure(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content:\n",
      "\n",
      "Academic Research Writing Dos and Don’ts\n",
      "Rules to Follow\n",
      "General:\n",
      "Do NOT use passive voice, pronouns, adverbs, or emotive language.\n",
      "Never begin a sentence with an acronym.\n",
      "Don’t use the same word twice in a sentence.\n",
      "Do NOT use prepositional phrases {PP} (or passive words) to start/begin a sentence.\n",
      "Do not write in first- or second person; always write in third person.\n",
      "Do NOT begin sentences using the words : this, these, in, that, with, a, an, and, it, is, its, it is (both upper case and lower case applied)\n",
      "Maximum sentence length is to be no longer than 22 words. Remove excessive words more than 22 words but still should have meaning\n",
      "Spell out numbers less than 10 unless associated with the body of your work.\n",
      "Don’t start sentence using a number.\n",
      "description\": \"Use 'a' or 'an' only based on the following word's pronunciation (e.g., 'an ethical', 'a useful tool')\",\n",
      "\"pattern\": \"\\\\b(a|an)\\\\b\n",
      "ACADEMIC RESEARCH WRITING EXPECTATIONS (ARWE)\n",
      "It includes both upper and lower case and combination of both for all the words\n",
      "Example Words, Phrases, and Syntax NOT to Use Don’t Use Passive Words in your research/technical writing\n",
      "Additionally, Many, Some, Better/Best\n",
      "Ah, May, Almost or Difficult, Might, Believe, Most\n",
      "Big/Small, Good/Bad, Happy/Sad Much, High/Low, Often, Can, be Plenty, Could / Could be Should\n",
      "Easy/Hard, More/Less->\n",
      "Frequently, Slow/Fast\n",
      "Generally speaking… Modern/Old\n",
      "He or She Mature way\n",
      "Heavy/Light These\n",
      "Here, They\n",
      "Hope, This is\n",
      "In, Very\n",
      "It, We\n",
      "Large or Small – Major or Minor With\n",
      "Long or Short Strongest/Weakest\n",
      "There, Finest\n",
      "Clearly or Meantime Normal or timely manner\n",
      "A fraction, Unique or Usually\n",
      "A lot Simple/Hard\n",
      "Avoid weasels words like weasel_words = [\n",
      "\"A bit\", \"A lot\", \"About\", \"Abstract\", \"Abundant\", \"According to\", \"Accurately\",\n",
      "\"Aim\", \"Ample\", \"Apparent\", \"Apparently\", \"Appearance\", \"Approach\", \"Approaching\",\n",
      "\"Approximately\", \"Apt\", \"Arguably\", \"Argue\", \"Around\", \"As long as\", \"Association\",\n",
      "\"Assume\", \"Assumed\", \"Assuming\", \"At least\", \"Barely\", \"Basically\", \"Belief\",\n",
      "\"Believe\", \"Best\", \"Big\", \"Borderline\", \"Broad\", \"Broadly\", \"But for\", \"Can\",\n",
      "\"Cannot be ruled out\", \"Certain\", \"Certainly\", \"Chiefly\", \"Circumstantial\",\n",
      "\"Claim\", \"Clearly\", \"Common\", \"Commonly\", \"Comparatively\", \"Conceivably\", \"Concludes\",\n",
      "\"Conclude\", \"Confirms\", \"Conjectural\", \"Connotes\", \"Considerable\", \"Consistent\",\n",
      "\"Consistent with\", \"Copious\", \"Correlates\", \"Correlates with\", \"Could\", \"Could also\",\n",
      "\"Could be\", \"Customarily\", \"Customary\", \"Denotes\", \"Despite\", \"Despite limitations\",\n",
      "\"Doubt\", \"Easily\", \"Dramatically\", \"Drawback\", \"Easy\", \"Efficient\", \"Essentially\",\n",
      "\"Estimate\", \"Estimation\", \"Etcetera\", \"Even if\", \"Evident\", \"Evidently\", \"Expect\",\n",
      "\"Extensive\", \"Extrapolate\", \"Extrapolation\", \"Fairly\", \"Faint\", \"Favorable\",\n",
      "\"Favorable trend\", \"Feasible\", \"Feasibly\", \"Few\", \"Fewer\", \"Figurative\", \"Figuratively\",\n",
      "\"Flexible\", \"Foresee\", \"Frequent\", \"Frequently\", \"General\", \"Generally\", \"Generous\",\n",
      "\"Guess\", \"Hardly\", \"Has a role\", \"Helps\", \"Helps maintain\", \"Highly\", \"Hypothetical\",\n",
      "\"Hypothetically\", \"If\", \"In other instances\", \"Implication\", \"Implies\", \"Implies might\",\n",
      "\"In a sense\", \"In general\", \"In our hands\", \"In some ways\", \"Inclination\", \"Indeed\",\n",
      "\"Indicative\", \"Indicates\", \"Indication\", \"Inference\", \"Infers\", \"Innumerable\",\n",
      "\"In spite of shortcomings\", \"Instead\", \"Intentional\", \"Is like\", \"Judgement\",\n",
      "\"Kind of\", \"Large\", \"Largely\", \"Layer of\", \"Less\", \"Likelihood\", \"Likely\", \"Link\",\n",
      "\"Linked\", \"Literally\", \"Looks\", \"Loosely\", \"Lots\", \"Mainly\", \"Maintains\", \"Marginal\",\n",
      "\"Maximize\", \"May\", \"May be\", \"Maybe\", \"More or less\", \"Most\", \"Mostly\", \"Multiple\",\n",
      "\"Myriad\", \"Naturally\", \"Nearly\", \"Never\", \"Nevertheless\", \"Nonetheless\", \"Normal\",\n",
      "\"Normally\", \"Not clear\", \"Not quite\", \"Numerous\", \"Obvious\", \"Obviously\", \"Of course\",\n",
      "\"Often\", \"Opinion\", \"Optimal\", \"Optimize\", \"Ordinarily\", \"Ordinary\", \"Our results\",\n",
      "\"Partially\", \"Perception\", \"Perceived\", \"Perfect\", \"Perfectly\", \"Perhaps\", \"Plentiful\",\n",
      "\"Plausible\", \"Posit\", \"Possible\", \"Possibly\", \"Postulate\", \"Postulated\", \"Potential\",\n",
      "\"Potentially\", \"Practically\", \"Practically\", \"Predict\", \"Predominant\", \"Predominantly\",\n",
      "\"Presumably\", \"Presume\", \"Presumed\", \"Presumption\", \"Prevalent\", \"Prevailing\",\n",
      "\"Principally\", \"Probability\", \"Probable\", \"Probably\", \"Propose\", \"Provided\",\n",
      "\"Proposes\", \"Putative\", \"Quite\", \"Rapid\", \"Rarely\", \"Rather\", \"Reasonably\",\n",
      "\"Regular\", \"Regularly\", \"Relatively\", \"Reliable\", \"Reportedly\", \"Represents\",\n",
      "\"Robust\", \"Roughly\", \"Routine\", \"Scarcely\", \"Secure\", \"Seemingly\", \"Seems\",\n",
      "\"Seen as\", \"Several\", \"Severe\", \"Shortcomings\", \"Should\", \"Signifies\", \"Significant\",\n",
      "\"Significantly\", \"Sizable\", \"Slightly\", \"Slow\", \"Some\", \"Somehow\", \"Somewhat\",\n",
      "\"Somewhat somewhat\", \"Someway\", \"Speculate\", \"Speculated\", \"Speculation\", \"Speculative\",\n",
      "\"Standard\", \"Statistical trend\", \"Still\", \"Strongly\", \"Strongly suggests\", \"Substantial\",\n",
      "\"Substantially\", \"Sufficient\", \"Suggest\", \"Suggestion\", \"Suppose\", \"Supposed\",\n",
      "\"Supposition\", \"Symbolic\", \"Tend\", \"Tendency\", \"Tending\", \"Tentative\", \"Tentatively\",\n",
      "\"That being said\", \"The best\", \"The fact that\", \"The opposite is also possible\",\n",
      "\"Theoretical\", \"Theoretically\", \"Though\", \"To my knowledge\", \"Traditional\", \"Trend\",\n",
      "\"Trending\", \"Typical\", \"Typically\", \"Ultimately\", \"Uncertain\", \"Unlikely\", \"Usual\",\n",
      "\"Usually\", \"Various\", \"Very closely\", \"Very likely\", \"Virtually\", \"Viewed in this way\",\n",
      "\"We propose\", \"Weakly\", \"Wide\", \"Widespread\", \"With all due respect\", \"Would appear\",\n",
      "\"Yet\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "def read_docx(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    return \"\\n\".join([para.text.strip() for para in doc.paragraphs if para.text.strip()])\n",
    "\n",
    "# Specify the path directly within the project folder\n",
    "file_path = os.path.join(\"rules\", \"Academic Research Writing Dos and Don.docx\")  # Adjust filename if needed\n",
    "\n",
    "# Read and store the extracted text\n",
    "example_rules = read_docx(file_path)\n",
    "\n",
    "# Print the full extracted content or a preview\n",
    "print(\"Extracted content:\\n\")\n",
    "print(example_rules)  # Preview first 1000 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZFXJ3gvi5y2T",
    "outputId": "407ef6a2-4626-4656-f84f-b1a10ffc3884"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===  Validated & Improved Regex Pattern List (Gemini) ===\n",
      "\n",
      "```python\n",
      "[\n",
      "    {\"pattern\": r\"(?i)\\b(a|an)\\b\\s+\\w+\", \"description\": \"Detects 'a' or 'an' followed by a word\"},\n",
      "    {\"pattern\": r\"(?i)^[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*\\b\", \"description\": \"Detects sentences starting with an acronym\"},\n",
      "    {\"pattern\": r\"(?i)\\b(\\w+)\\s+\\1\\b\", \"description\": \"Detects repeated words in a sentence\"},\n",
      "    {\"pattern\": r\"(?i)^(?:(?:in|that|with|a|an|and|it|is|its|this|these|it is)\\s+)\", \"description\": \"Detects sentences starting with forbidden words\"},\n",
      "    {\"pattern\": r\"(?i)^(?:(?:this|these|in|that|with|a|an|and|it|is|its|it is)\\s+)\", \"description\": \"Detects sentences starting with forbidden words\"},\n",
      "    {\"pattern\": r\"(?i)^(?:(?:this|these|in|that|with|a|an|and|it|is|its|it is)\\s+)\", \"description\": \"Detects sentences starting with forbidden words\"},\n",
      "    {\"pattern\": r\"(?i)\\b(\\w+)\\s+\\1\\b\", \"description\": \"Detects repeated words in a sentence\"},\n",
      "    {\"pattern\": r\"(?i)^(?:\\w+\\s+){22,}\\w+\", \"description\": \"Detects sentences longer than 22 words\"},\n",
      "    {\"pattern\": r\"(?i)^[0-9]\\s+\\w+\", \"description\": \"Detects sentences starting with a number\"},\n",
      "    {\"pattern\": r\"(?i)\\b(?:(?:a|an)\\s+)?(?:(?:in|that|with|a|an|and|it|is|its|this|these)\\s+)+\\w+\", \"description\": \"Detects sentences starting with forbidden words, optionally preceded by 'a' or 'an'\"},\n",
      "    {\"pattern\": r\"(?i)\\b(?:(?:a|an)\\s+)?(?:(?:this|these|in|that|with|a|an|and|it|is|its|it is)\\s+)+\\w+\", \"description\": \"Detects sentences starting with forbidden words, optionally preceded by 'a' or 'an'\"},\n",
      "    {\"pattern\": r\"(?i)\\b(?:(?:a|an)\\s+)?(?:(?:this|these|in|that|with|a|an|and|it|is|its|it is)\\s+)+\\w+\", \"description\": \"Detects sentences starting with forbidden words, optionally preceded by 'a' or 'an'\"},\n",
      "    {\"pattern\": r\"(?i)\\b(Additionally|Many|Some|Better|Best|Ah|May|Almost|Difficult|Might|Believe|Most|Big|Small|Good|Bad|Happy|Sad|Much|High|Low|Often|Can|be|Plenty|Could|Could be|Should|Easy|Hard|More|Less|Frequently|Slow|Fast|Generally speaking…|Modern|Old|He|She|Heavy|Light|Here|They|Hope|This is|In|Very|It|We|Large|Small|Major|Minor|With|Long|Short|Strongest|Weakest|There|Finest|Clearly|Meantime|Normal|timely manner|A fraction|Unique|Usually|A lot|Simple|Hard)\\b\", \"description\": \"Detects words not to be used at the start of a sentence\"},\n",
      "    {\"pattern\": r\"(?i)\\b(?:A bit|A lot|About|Abstract|Abundant|According to|Accurately|Aim|Ample|Apparent|Apparently|Appearance|Approach|Approaching|Approximately|Apt|Arguably|Argue|Around|As long as|Association|Assume|Assumed|Assuming|At least|Barely|Basically|Belief|Believe|Best|Big|Borderline|Broad|Broadly|But for|Can|Cannot be ruled out|Certain|Certainly|Chiefly|Circumstantial|Claim|Clearly|Common|Commonly|Comparatively|Conceivably|Concludes|Conclude|Confirms|Conjectural|Connotes|Considerable|Consistent|Consistent with|Copious|Correlates|Correlates with|Could|Could also|Could be|Customarily|Customary|Denotes|Despite|Despite limitations|Doubt|Easily|Dramatically|Drawback|Easy|Efficient|Essentially|Estimate|Estimation|Etcetera|Even if|Evident|Evidently|Expect|Extensive|Extrapolate|Extrapolation|Fairly|Faint|Favorable|Favorable trend|Feasible|Feasibly|Few|Fewer|Figurative|Figuratively|Flexible|Foresee|Frequent|Frequently|General|Generally|Generous|Guess|Hardly|Has a role|Helps|Helps maintain|Highly|Hypothetical|Hypothetically|If|In other instances|Implication|Implies|Implies might|In a sense|In general|In our hands|In some ways|Inclination|Indeed|Indicative|Indicates|Indication|Inference|Infers|Innumerable|In spite of shortcomings|Instead|Intentional|Is like|Judgement|Kind of|Large|Largely|Layer of|Less|Likelihood|Likely|Link|Linked|Literally|Looks|Loosely|Lots|Mainly|Maintains|Marginal|Maximize|May|May be|Maybe|More or less|Most|Mostly|Multiple|Myriad|Naturally|Nearly|Never|Nevertheless|Nonetheless|Normal|Normally|Not clear|Not quite|Numerous|Obvious|Obviously|Of course|Often|Opinion|Optimal|Optimize|Ordinarily|Ordinary|Our results|Partially|Perception|Perceived|Perfect|Perfectly|Perhaps|Plentiful|Plausible|Posit|Possible|Possibly|Postulate|Postulated|Potential|Potentially|Practically|Practically|Predict|Predominant|Predominantly|Presumably|Presume|Presumed|Presumption|Prevalent|Prevailing|Principally|Probability|Probable|Probably|Propose|Provided|Proposes|Putative|Quite|Rapid|Rarely|Rather|Reasonably|Regular|Regularly|Relatively|Reliable|Reportedly|Represents|Robust|Roughly|Routine|Scarcely|Secure|Seemingly|Seems|Seen as|Several|Severe|Shortcomings|Should|Signifies|Significant|Significantly|Sizable|Slightly|Slow|Some|Somehow|Somewhat|Somewhat somewhat|Someway|Speculate|Speculated|Speculation|Speculative|Standard|Statistical trend|Still|Strongly|Strongly suggests|Substantial|Substantially|Sufficient|Suggest|Suggestion|Suppose|Supposed|Supposition|Symbolic|Tend|Tendency|Tending|Tentative|Tentatively|That being said|The best|The fact that|The opposite is also possible|Theoretical|Theoretically|Though|To my knowledge|Traditional|Trend|Trending|Typical|Typically|Ultimately|Uncertain|Unlikely|Usual|Usually|Various|Very closely|Very likely|Virtually|Viewed in this way|We propose|Weakly|Wide|Widespread|With all due respect|Would appear|Yet)\\b\", \"description\": \"Detects weasel words\"}\n",
      "]\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt to get regex patterns with descriptions\n",
    "system_prompt = \"You are a regex generator. Given writing rules or examples, output Python regex patterns along with their short descriptions to detect them.\"\n",
    "\n",
    "user_prompt = f\"\"\"\n",
    "Here are the writing rules or examples:\n",
    "\n",
    "{example_rules}\n",
    "\n",
    "Generate Python regex patterns and a short description for each, output as a Python list of dictionaries in the following format:\n",
    "[\n",
    "    {{\"pattern\": r'pattern_here', \"description\": \"short description here\"}},\n",
    "    ...\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "model = genai.GenerativeModel('gemini-2.0-flash-lite')\n",
    "response = model.generate_content(f\"{system_prompt}\\n\\n{user_prompt}\")\n",
    "\n",
    "generated_pattern_list = response.text\n",
    "# Prompt to validate and optimize regex patterns\n",
    "validator_system_prompt = \"\"\"\n",
    "You are a regex validator and optimizer. Given a list of regex patterns and writing rules:\n",
    "- Improve the regex patterns if needed.\n",
    "- Ensure all patterns are case-insensitive by adding (?i) at the start of the pattern.\n",
    "- Only return a valid Python list of dictionaries.\n",
    "- Do not include explanations, code comments, or markdown formatting.\n",
    "- Do not assign the list to any variable.\n",
    "\n",
    "Return strictly this format:\n",
    "\n",
    "[\n",
    "    {\"pattern\": r'regex_here', \"description\": \"short explanation\"},\n",
    "    ...\n",
    "]\n",
    "\"\"\"\n",
    "validator_user_prompt = f\"\"\"\n",
    "Writing Rules:\n",
    "\n",
    "{example_rules}\n",
    "\n",
    "Generated Regex Patterns:\n",
    "\n",
    "{generated_pattern_list}\n",
    "\n",
    "Please review and improve the patterns. Return the updated list in this format:\n",
    "\n",
    "[\n",
    "    {{\"pattern\": r'pattern_here', \"description\": \"short description here\"}},\n",
    "    ...\n",
    "]\n",
    "\n",
    "Optionally explain the improvements you made.\n",
    "\"\"\"\n",
    "\n",
    "# Run Validator Prompt using Gemini\n",
    "model = genai.GenerativeModel('gemini-1.5-flash-latest', generation_config={\"temperature\": 0.0})\n",
    "response = model.generate_content(f\"{validator_system_prompt}\\n\\n{validator_user_prompt}\")\n",
    "\n",
    "validated_pattern_list = response.text\n",
    "print(\"\\n===  Validated & Improved Regex Pattern List (Gemini) ===\\n\")\n",
    "print(validated_pattern_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully parsed pattern list.\n"
     ]
    }
   ],
   "source": [
    "# Extract the part between the first [ and last ]\n",
    "list_match = re.search(r'(\\[.*\\])', validated_pattern_list, re.DOTALL)\n",
    "\n",
    "if list_match:\n",
    "    clean_list_str = list_match.group(1)\n",
    "    try:\n",
    "        parsed_pattern_list = ast.literal_eval(clean_list_str)\n",
    "        print(\" Successfully parsed pattern list.\")\n",
    "    except Exception as e:\n",
    "        print(\" Failed to parse pattern list:\", e)\n",
    "        parsed_pattern_list = []\n",
    "else:\n",
    "    print(\" No valid list found in generated content.\")\n",
    "    parsed_pattern_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'pattern': '(?i)\\\\b(a|an)\\\\b\\\\s+\\\\w+', 'description': \"Detects 'a' or 'an' followed by a word\"}, {'pattern': '(?i)^[A-Z][a-z]+(?:\\\\s+[A-Z][a-z]+)*\\\\b', 'description': 'Detects sentences starting with an acronym'}, {'pattern': '(?i)\\\\b(\\\\w+)\\\\s+\\\\1\\\\b', 'description': 'Detects repeated words in a sentence'}, {'pattern': '(?i)^(?:(?:in|that|with|a|an|and|it|is|its|this|these|it is)\\\\s+)', 'description': 'Detects sentences starting with forbidden words'}, {'pattern': '(?i)^(?:(?:this|these|in|that|with|a|an|and|it|is|its|it is)\\\\s+)', 'description': 'Detects sentences starting with forbidden words'}, {'pattern': '(?i)^(?:(?:this|these|in|that|with|a|an|and|it|is|its|it is)\\\\s+)', 'description': 'Detects sentences starting with forbidden words'}, {'pattern': '(?i)\\\\b(\\\\w+)\\\\s+\\\\1\\\\b', 'description': 'Detects repeated words in a sentence'}, {'pattern': '(?i)^(?:\\\\w+\\\\s+){22,}\\\\w+', 'description': 'Detects sentences longer than 22 words'}, {'pattern': '(?i)^[0-9]\\\\s+\\\\w+', 'description': 'Detects sentences starting with a number'}, {'pattern': '(?i)\\\\b(?:(?:a|an)\\\\s+)?(?:(?:in|that|with|a|an|and|it|is|its|this|these)\\\\s+)+\\\\w+', 'description': \"Detects sentences starting with forbidden words, optionally preceded by 'a' or 'an'\"}, {'pattern': '(?i)\\\\b(?:(?:a|an)\\\\s+)?(?:(?:this|these|in|that|with|a|an|and|it|is|its|it is)\\\\s+)+\\\\w+', 'description': \"Detects sentences starting with forbidden words, optionally preceded by 'a' or 'an'\"}, {'pattern': '(?i)\\\\b(?:(?:a|an)\\\\s+)?(?:(?:this|these|in|that|with|a|an|and|it|is|its|it is)\\\\s+)+\\\\w+', 'description': \"Detects sentences starting with forbidden words, optionally preceded by 'a' or 'an'\"}, {'pattern': '(?i)\\\\b(Additionally|Many|Some|Better|Best|Ah|May|Almost|Difficult|Might|Believe|Most|Big|Small|Good|Bad|Happy|Sad|Much|High|Low|Often|Can|be|Plenty|Could|Could be|Should|Easy|Hard|More|Less|Frequently|Slow|Fast|Generally speaking…|Modern|Old|He|She|Heavy|Light|Here|They|Hope|This is|In|Very|It|We|Large|Small|Major|Minor|With|Long|Short|Strongest|Weakest|There|Finest|Clearly|Meantime|Normal|timely manner|A fraction|Unique|Usually|A lot|Simple|Hard)\\\\b', 'description': 'Detects words not to be used at the start of a sentence'}, {'pattern': '(?i)\\\\b(?:A bit|A lot|About|Abstract|Abundant|According to|Accurately|Aim|Ample|Apparent|Apparently|Appearance|Approach|Approaching|Approximately|Apt|Arguably|Argue|Around|As long as|Association|Assume|Assumed|Assuming|At least|Barely|Basically|Belief|Believe|Best|Big|Borderline|Broad|Broadly|But for|Can|Cannot be ruled out|Certain|Certainly|Chiefly|Circumstantial|Claim|Clearly|Common|Commonly|Comparatively|Conceivably|Concludes|Conclude|Confirms|Conjectural|Connotes|Considerable|Consistent|Consistent with|Copious|Correlates|Correlates with|Could|Could also|Could be|Customarily|Customary|Denotes|Despite|Despite limitations|Doubt|Easily|Dramatically|Drawback|Easy|Efficient|Essentially|Estimate|Estimation|Etcetera|Even if|Evident|Evidently|Expect|Extensive|Extrapolate|Extrapolation|Fairly|Faint|Favorable|Favorable trend|Feasible|Feasibly|Few|Fewer|Figurative|Figuratively|Flexible|Foresee|Frequent|Frequently|General|Generally|Generous|Guess|Hardly|Has a role|Helps|Helps maintain|Highly|Hypothetical|Hypothetically|If|In other instances|Implication|Implies|Implies might|In a sense|In general|In our hands|In some ways|Inclination|Indeed|Indicative|Indicates|Indication|Inference|Infers|Innumerable|In spite of shortcomings|Instead|Intentional|Is like|Judgement|Kind of|Large|Largely|Layer of|Less|Likelihood|Likely|Link|Linked|Literally|Looks|Loosely|Lots|Mainly|Maintains|Marginal|Maximize|May|May be|Maybe|More or less|Most|Mostly|Multiple|Myriad|Naturally|Nearly|Never|Nevertheless|Nonetheless|Normal|Normally|Not clear|Not quite|Numerous|Obvious|Obviously|Of course|Often|Opinion|Optimal|Optimize|Ordinarily|Ordinary|Our results|Partially|Perception|Perceived|Perfect|Perfectly|Perhaps|Plentiful|Plausible|Posit|Possible|Possibly|Postulate|Postulated|Potential|Potentially|Practically|Practically|Predict|Predominant|Predominantly|Presumably|Presume|Presumed|Presumption|Prevalent|Prevailing|Principally|Probability|Probable|Probably|Propose|Provided|Proposes|Putative|Quite|Rapid|Rarely|Rather|Reasonably|Regular|Regularly|Relatively|Reliable|Reportedly|Represents|Robust|Roughly|Routine|Scarcely|Secure|Seemingly|Seems|Seen as|Several|Severe|Shortcomings|Should|Signifies|Significant|Significantly|Sizable|Slightly|Slow|Some|Somehow|Somewhat|Somewhat somewhat|Someway|Speculate|Speculated|Speculation|Speculative|Standard|Statistical trend|Still|Strongly|Strongly suggests|Substantial|Substantially|Sufficient|Suggest|Suggestion|Suppose|Supposed|Supposition|Symbolic|Tend|Tendency|Tending|Tentative|Tentatively|That being said|The best|The fact that|The opposite is also possible|Theoretical|Theoretically|Though|To my knowledge|Traditional|Trend|Trending|Typical|Typically|Ultimately|Uncertain|Unlikely|Usual|Usually|Various|Very closely|Very likely|Virtually|Viewed in this way|We propose|Weakly|Wide|Widespread|With all due respect|Would appear|Yet)\\\\b', 'description': 'Detects weasel words'}]\n"
     ]
    }
   ],
   "source": [
    "print(parsed_pattern_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "g2sdOHR9qWDi",
    "outputId": "c967b72f-7531-40e9-f501-9bc29719a40d"
   },
   "outputs": [],
   "source": [
    "def analyze_sentence(sentence, pattern_list):\n",
    "    SYSTEM_PROMPT = \"\"\"You are a professional text editor that follows strict formatting rules. Always:\n",
    "1. Analyze the sentence for pattern matches using these rules:\n",
    "{patterns_list}\n",
    "2. List each pattern matched with example matches.\n",
    "3. Specify required changes.\n",
    "\n",
    "Respond in this exact structure:\n",
    "[Analysis]\n",
    "- List each pattern matched with example matches\n",
    "- Specify required changes\n",
    "\"\"\"\n",
    "\n",
    "    formatted_rules = \"\\n\".join([f\"- {p['description']} (Pattern: {p['pattern']})\" for p in pattern_list])\n",
    "    full_prompt = f\"{SYSTEM_PROMPT.format(patterns_list=formatted_rules)}\\n\\nOriginal sentence:\\n{sentence}\\n\"\n",
    "\n",
    "    try:\n",
    "        model = genai.GenerativeModel('gemini-2.0-flash-lite')\n",
    "        response = model.generate_content(full_prompt)\n",
    "        response_text = response.text\n",
    "\n",
    "        # Extract analysis only\n",
    "        analysis = re.search(r'\\[Analysis\\](.*)', response_text, re.DOTALL)\n",
    "        analysis_text = analysis.group(1).strip() if analysis else response_text.strip()\n",
    "\n",
    "        return {\n",
    "            \"original\": sentence,\n",
    "            \"analysis\": analysis_text\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"LLM error: {e}\")\n",
    "        return {\n",
    "            \"original\": sentence,\n",
    "            \"analysis\": \"Error during LLM analysis.\"\n",
    "        }\n",
    "\n",
    "# --- Main workflow ---\n",
    "results = []\n",
    "for sentence in all_sentences:\n",
    "    result = analyze_sentence(sentence, parsed_pattern_list)\n",
    "    results.append(result)\n",
    "\n",
    "# Print only the analysis for each sentence\n",
    "print(\"====Analysis for Each Sentence====\")\n",
    "for r in results:\n",
    "    print(f\"Original: {r['original']}\")\n",
    "    print(f\"Analysis: {r['analysis']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "K9XuzcfiolVZ",
    "outputId": "f9be7bc4-fb73-4709-8ad1-554d475f3ccf"
   },
   "outputs": [],
   "source": [
    "def rewrite_sentence(sentence, pattern_list):\n",
    "    SYSTEM_PROMPT = \"\"\"You are a professional text editor that follows strict formatting rules.\n",
    "Rewrite the sentence to avoid ALL pattern matches according to these rules:\n",
    "{patterns_list}\n",
    "- Maintain original formatting where possible.\n",
    "- Preserve the original meaning.\n",
    "- validiate the rewritten output again with regex pattern\n",
    "\n",
    "Respond with ONLY the rewritten sentence and nothing else.\"\"\"\n",
    "\n",
    "    formatted_rules = \"\\n\".join([f\"- {p['description']} (Pattern: {p['pattern']})\" for p in pattern_list])\n",
    "    full_prompt = SYSTEM_PROMPT.format(patterns_list=formatted_rules) + f\"\\n\\nOriginal sentence:\\n{sentence}\\n\"\n",
    "\n",
    "    try:\n",
    "        model = genai.GenerativeModel('gemini-2.0-flash-lite')\n",
    "        response = model.generate_content(full_prompt)\n",
    "        rewritten_sentence = response.text.strip()\n",
    "        return {sentence: rewritten_sentence}\n",
    "    except Exception as e:\n",
    "        print(f\"LLM error: {e}\")\n",
    "        return {sentence: sentence}\n",
    "\n",
    "# --- Main workflow ---\n",
    "rewritten_sentences = {}\n",
    "for sentence in sentences:\n",
    "    result = rewrite_sentence(sentence, parsed_pattern_list)\n",
    "    rewritten_sentences.update(result)\n",
    "\n",
    "print(\"====Original Text====\")\n",
    "for sentence in rewritten_sentences.keys():\n",
    "    print(sentence)\n",
    "print(\"====Rewritten sentences Text====\")\n",
    "for sentence in rewritten_sentences.values():\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
