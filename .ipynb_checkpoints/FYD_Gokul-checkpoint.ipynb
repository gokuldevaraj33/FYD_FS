{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "siU6MLd-YN9s"
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import docx\n",
    "import re\n",
    "from docx import Document\n",
    "from docx.table import Table\n",
    "from docx.text.paragraph import Paragraph\n",
    "from docx.oxml.ns import qn\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_block_items(doc):\n",
    "    for block in doc.element.body:\n",
    "        if block.tag.endswith('}p'):\n",
    "            yield Paragraph(block, doc)\n",
    "        elif block.tag.endswith('}tbl'):\n",
    "            yield Table(block, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_image(paragraph):\n",
    "    return any('graphic' in r.tag.lower() for r in paragraph._element.iter())\n",
    "\n",
    "def extract_images_from_paragraph(paragraph):\n",
    "    image_bytes_list = []\n",
    "    for shape in paragraph._element.iter():\n",
    "        if shape.tag.endswith('}blip'):\n",
    "            rId = shape.get(qn('r:embed'))\n",
    "            image_part = paragraph.part.related_parts[rId]\n",
    "            image_bytes = image_part.blob\n",
    "            image_bytes_list.append(image_bytes)\n",
    "    return image_bytes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_block_items(doc):\n",
    "    for block in doc.element.body:\n",
    "        tag = block.tag.lower()\n",
    "        if tag.endswith('}p'):\n",
    "            yield Paragraph(block, doc)\n",
    "        elif tag.endswith('}tbl'):\n",
    "            yield Table(block, doc)\n",
    "        elif tag.endswith('}sectpr'):\n",
    "            continue  # skip section properties\n",
    "        else:\n",
    "            yield block\n",
    "\n",
    "def has_image(paragraph):\n",
    "    return any('graphic' in r.tag.lower() for r in paragraph._element.iter())\n",
    "\n",
    "def extract_images_from_paragraph(paragraph):\n",
    "    image_bytes_list = []\n",
    "    for shape in paragraph._element.iter():\n",
    "        if shape.tag.endswith('}blip'):\n",
    "            rId = shape.get(qn('r:embed'))\n",
    "            image_part = paragraph.part.related_parts[rId]\n",
    "            image_bytes = image_part.blob\n",
    "            image_bytes_list.append(image_bytes)\n",
    "    return image_bytes_list\n",
    "\n",
    "def contains_equation(paragraph):\n",
    "    for elem in paragraph._element.iter():\n",
    "        if \"oMath\" in elem.tag or \"oMathPara\" in elem.tag:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def scan_document():\n",
    "    global input_path\n",
    "    input_path = 'documents/input.docx'\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"Input file not found: {input_path}\")\n",
    "        return\n",
    "\n",
    "    doc = Document(input_path)\n",
    "    print(\"Scanning Document...\\n\")\n",
    "\n",
    "    image_counter = 1\n",
    "\n",
    "    for block in iter_block_items(doc):\n",
    "        if isinstance(block, Paragraph):\n",
    "            text = block.text.strip()[:60]\n",
    "            style = block.style.name.lower()\n",
    "\n",
    "            if contains_equation(block):\n",
    "                print(f\"Equation: {text}\")\n",
    "            elif 'heading' in style:\n",
    "                match = re.search(r'heading (\\d+)', style)\n",
    "                if match:\n",
    "                    print(f\"Heading {match.group(1)}: {text}\")\n",
    "                else:\n",
    "                    print(f\"Heading (untyped): {text}\")\n",
    "            elif 'caption' in style:\n",
    "                print(f\"Caption: {text}\")\n",
    "            elif text:\n",
    "                print(f\"Paragraph: {text}\")\n",
    "            else:\n",
    "                print(\"Empty Paragraph\")\n",
    "\n",
    "            if has_image(block):\n",
    "                images = extract_images_from_paragraph(block)\n",
    "                for img_bytes in images:\n",
    "                    try:\n",
    "                        img = Image.open(BytesIO(img_bytes))\n",
    "                        print(f\"Image {image_counter} — Format: {img.format}, Size: {img.size}\")\n",
    "                        image_counter += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"Failed to load image: {e}\")\n",
    "\n",
    "        elif isinstance(block, Table):\n",
    "            print(\"Table\")\n",
    "\n",
    "        else:\n",
    "            raw_tag = block.tag if hasattr(block, 'tag') else str(type(block))\n",
    "            print(f\"Unknown Block — Tag: {raw_tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_document()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_paragraphs(file_path):\n",
    "    doc = Document(file_path)\n",
    "    paragraphs = []\n",
    "    for para in doc.paragraphs:\n",
    "        style = para.style.name.lower()\n",
    "        if style in [\"normal\", \"body text\"]:  # Only include plain paragraphs\n",
    "            text = para.text.strip()\n",
    "            if text:\n",
    "                paragraphs.append(text)\n",
    "    return paragraphs\n",
    "\n",
    "paragraph_list = extract_paragraphs(input_path)\n",
    "\n",
    "# Preview first few paragraphs\n",
    "for i, p in enumerate(paragraph_list[:]):\n",
    "    print(f\"Paragraph {i+1}: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_sentence_split(text):\n",
    "    # Splits on period, question mark, or exclamation, followed by space and a capital letter\n",
    "    return re.split(r'(?<=[\\.\\?\\!])\\s+(?=[A-Z])', text)\n",
    "\n",
    "# paragraph_list is assumed to be already defined\n",
    "all_sentences = []\n",
    "\n",
    "for paragraph in paragraph_list:\n",
    "    sentences = simple_sentence_split(paragraph)\n",
    "    all_sentences.extend(sentences)\n",
    "\n",
    "print(f\"Split into {len(all_sentences)} total sentences.\\n\")\n",
    "\n",
    "for idx, sentence in enumerate(all_sentences, start=1):\n",
    "    print(f\"Sentence {idx}: {sentence}\"+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your Gemini API Key manually\n",
    "GEMINI_API_KEY = \"AIzaSyBe5DwsXc49gaHO51YRNCdLhZlAc2v4v7I\"  # Replace with your actual API key\n",
    "genai.configure(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_docx(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    return \"\\n\".join([para.text.strip() for para in doc.paragraphs if para.text.strip()])\n",
    "\n",
    "# Specify the path directly within the project folder\n",
    "file_path = os.path.join(\"\", \"Academic Research Writing Dos and Don.docx\")  # Adjust filename if needed\n",
    "\n",
    "# Read and store the extracted text\n",
    "example_rules = read_docx(file_path)\n",
    "\n",
    "# Print the full extracted content or a preview\n",
    "print(\"Extracted content:\\n\")\n",
    "print(example_rules)  # Preview first 1000 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZFXJ3gvi5y2T",
    "outputId": "407ef6a2-4626-4656-f84f-b1a10ffc3884"
   },
   "outputs": [],
   "source": [
    "# Prompt to get regex patterns with descriptions\n",
    "system_prompt = \"You are a regex generator. Given writing rules or examples, output Python regex patterns along with their short descriptions to detect them.\"\n",
    "\n",
    "user_prompt = f\"\"\"\n",
    "Here are the writing rules or examples:\n",
    "\n",
    "{example_rules}\n",
    "\n",
    "Generate Python regex patterns and a short description for each, output as a Python list of dictionaries in the following format:\n",
    "[\n",
    "    {{\"pattern\": r'pattern_here', \"description\": \"short description here\"}},\n",
    "    ...\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "model = genai.GenerativeModel('gemini-2.0-flash-lite')\n",
    "response = model.generate_content(f\"{system_prompt}\\n\\n{user_prompt}\")\n",
    "\n",
    "generated_pattern_list = response.text\n",
    "# Prompt to validate and optimize regex patterns\n",
    "validator_system_prompt = \"\"\"\n",
    "You are a regex validator and optimizer. Given a list of regex patterns and writing rules:\n",
    "- Improve the regex patterns if needed.\n",
    "- Ensure all patterns are case-insensitive by adding (?i) at the start of the pattern.\n",
    "- Only return a valid Python list of dictionaries.\n",
    "- Do not include explanations, code comments, or markdown formatting.\n",
    "- Do not assign the list to any variable.\n",
    "\n",
    "Return strictly this format:\n",
    "\n",
    "[\n",
    "    {\"pattern\": r'regex_here', \"description\": \"short explanation\"},\n",
    "    ...\n",
    "]\n",
    "\"\"\"\n",
    "validator_user_prompt = f\"\"\"\n",
    "Writing Rules:\n",
    "\n",
    "{example_rules}\n",
    "\n",
    "Generated Regex Patterns:\n",
    "\n",
    "{generated_pattern_list}\n",
    "\n",
    "Please review and improve the patterns. Return the updated list in this format:\n",
    "\n",
    "[\n",
    "    {{\"pattern\": r'pattern_here', \"description\": \"short description here\"}},\n",
    "    ...\n",
    "]\n",
    "\n",
    "Optionally explain the improvements you made.\n",
    "\"\"\"\n",
    "\n",
    "# Run Validator Prompt using Gemini\n",
    "model = genai.GenerativeModel('gemini-2.0-flash-lite')\n",
    "response = model.generate_content(f\"{validator_system_prompt}\\n\\n{validator_user_prompt}\")\n",
    "\n",
    "validated_pattern_list = response.text\n",
    "print(\"\\n===  Validated & Improved Regex Pattern List (Gemini) ===\\n\")\n",
    "print(validated_pattern_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the part between the first [ and last ]\n",
    "list_match = re.search(r'(\\[.*\\])', validated_pattern_list, re.DOTALL)\n",
    "\n",
    "if list_match:\n",
    "    clean_list_str = list_match.group(1)\n",
    "    try:\n",
    "        parsed_pattern_list = ast.literal_eval(clean_list_str)\n",
    "        print(\" Successfully parsed pattern list.\")\n",
    "    except Exception as e:\n",
    "        print(\" Failed to parse pattern list:\", e)\n",
    "        parsed_pattern_list = []\n",
    "else:\n",
    "    print(\" No valid list found in generated content.\")\n",
    "    parsed_pattern_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "g2sdOHR9qWDi",
    "outputId": "c967b72f-7531-40e9-f501-9bc29719a40d"
   },
   "outputs": [],
   "source": [
    "def analyze_sentence(sentence, pattern_list):\n",
    "    SYSTEM_PROMPT = \"\"\"You are a professional text editor that follows strict formatting rules. Always:\n",
    "1. Analyze the sentence for pattern matches using these rules:\n",
    "{patterns_list}\n",
    "2. List each pattern matched with example matches.\n",
    "3. Specify required changes.\n",
    "\n",
    "Respond in this exact structure:\n",
    "[Analysis]\n",
    "- List each pattern matched with example matches\n",
    "- Specify required changes\n",
    "\"\"\"\n",
    "\n",
    "    formatted_rules = \"\\n\".join([f\"- {p['description']} (Pattern: {p['pattern']})\" for p in pattern_list])\n",
    "    full_prompt = f\"{SYSTEM_PROMPT.format(patterns_list=formatted_rules)}\\n\\nOriginal sentence:\\n{sentence}\\n\"\n",
    "\n",
    "    try:\n",
    "        model = genai.GenerativeModel('gemini-2.0-flash-lite')\n",
    "        response = model.generate_content(full_prompt)\n",
    "        response_text = response.text\n",
    "\n",
    "        # Extract analysis only\n",
    "        analysis = re.search(r'\\[Analysis\\](.*)', response_text, re.DOTALL)\n",
    "        analysis_text = analysis.group(1).strip() if analysis else response_text.strip()\n",
    "\n",
    "        return {\n",
    "            \"original\": sentence,\n",
    "            \"analysis\": analysis_text\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"LLM error: {e}\")\n",
    "        return {\n",
    "            \"original\": sentence,\n",
    "            \"analysis\": \"Error during LLM analysis.\"\n",
    "        }\n",
    "\n",
    "# --- Main workflow ---\n",
    "results = []\n",
    "for sentence in all_sentences:\n",
    "    result = analyze_sentence(sentence, parsed_pattern_list)\n",
    "    results.append(result)\n",
    "\n",
    "# Print only the analysis for each sentence\n",
    "print(\"====Analysis for Each Sentence====\")\n",
    "for r in results:\n",
    "    print(f\"Original: {r['original']}\")\n",
    "    print(f\"Analysis: {r['analysis']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "K9XuzcfiolVZ",
    "outputId": "f9be7bc4-fb73-4709-8ad1-554d475f3ccf"
   },
   "outputs": [],
   "source": [
    "def rewrite_sentence(sentence, pattern_list):\n",
    "    SYSTEM_PROMPT = \"\"\"You are a professional text editor that follows strict formatting rules.\n",
    "Rewrite the sentence to avoid ALL pattern matches according to these rules:\n",
    "{patterns_list}\n",
    "- Maintain original formatting where possible.\n",
    "- Preserve the original meaning.\n",
    "- validiate the rewritten output again with regex pattern\n",
    "\n",
    "Respond with ONLY the rewritten sentence and nothing else.\"\"\"\n",
    "\n",
    "    formatted_rules = \"\\n\".join([f\"- {p['description']} (Pattern: {p['pattern']})\" for p in pattern_list])\n",
    "    full_prompt = SYSTEM_PROMPT.format(patterns_list=formatted_rules) + f\"\\n\\nOriginal sentence:\\n{sentence}\\n\"\n",
    "\n",
    "    try:\n",
    "        model = genai.GenerativeModel('gemini-2.0-flash-lite')\n",
    "        response = model.generate_content(full_prompt)\n",
    "        rewritten_sentence = response.text.strip()\n",
    "        return {sentence: rewritten_sentence}\n",
    "    except Exception as e:\n",
    "        print(f\"LLM error: {e}\")\n",
    "        return {sentence: sentence}\n",
    "\n",
    "# --- Main workflow ---\n",
    "rewritten_sentences = {}\n",
    "for sentence in sentences:\n",
    "    result = rewrite_sentence(sentence, parsed_pattern_list)\n",
    "    rewritten_sentences.update(result)\n",
    "\n",
    "print(\"====Original Text====\")\n",
    "for sentence in rewritten_sentences.keys():\n",
    "    print(sentence)\n",
    "print(\"====Rewritten sentences Text====\")\n",
    "for sentence in rewritten_sentences.values():\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
